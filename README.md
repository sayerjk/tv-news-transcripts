# TV News Audit

Many TV networks post their daily news show transcripts online, and have been doing so for many years. The goldmine here would be finding matching phrases and sentiments being pushed across different networks at uniform dates and times. For this, later implementation of [NLTK's](https://www.nltk.org/howto/collocations.html) bigrams and trigrams extraction functions will be used. The plan is to compare shows on the same network, on different networks, and [sentiment/subjectivity](https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis) metrics over a long period of time. Additionally, to find matching phrases, comparision of found phrases across shows during similar datetimes will be needed. Visualizations may help here, and topic analysis may provide more insight if exact phrases are not matching. However, despite the large volume of text per doucment, topic analysis may prove inaccurate for finding matching phrases since the way it divides topics (LDA topic modeling) often yields indistinct categories, despite the computer insisting distinct differences. 

Further analysis revealed many neutral values (exactly 0.0), and many of these sentences labeled 0.0 for polaritry are clearly not neutral. Death and murder mentioned in sentences is being ranked neutral. Understandably, TextBlob was not build specifically for television news, so this is not a complete surprise. I would now like to more closely examine the polarity scores for each individual sentence, rather than rely on the cumulative score based on the entire body of text. What percentage of all sentences are coming back as 0.0 neutral? It appears something like 30% from samples I've seen. When does the text become too abstract or reliant on context, such that the algogrithm cannot find any meaning beyond 0.0? This highlights the limitations of NLP. While we are not yet running fully automated psychotherapy sessions, NLP still proves valuable for more simple textual analysis, like Yelp reviews and social media posts. 
